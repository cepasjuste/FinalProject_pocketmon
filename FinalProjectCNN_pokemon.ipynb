{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "cc87c99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#URL: https://www.kaggle.com/datasets/lantian773030/pokemonclassification\n",
    "\n",
    "# 기존 프로젝트: 켓몬 149마리의 이미지 데이터 셋을 흑백 이미지로 변환하여 \n",
    "# 분류 및 MLP,CNN 방식으로 학습하여 47%의 정확도를 얻음\n",
    "\n",
    "#트레이닝 데이터 80%\n",
    "#테스트 데이터 20%\n",
    "\n",
    "#캐글에 올라온 예제를 일부 변경하여 성능 개선 시도\n",
    "#합성곱 레이어를 늘려서 좀 더 복잡한 패턴을 만든다.\n",
    "#optimizer 파라미터를 조절하면서 최적을 찾는다.\n",
    "#batch 파라미터를 조절하면서 최적을 찾는다.\n",
    "#epoch 파라미터를 조절하면서 최적을 찾는다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "13f0088f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os #os 모듈 가져오기\n",
    "import random \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm #notebook 자동으로 진행상태를 시각적으로 보여주는 라이브러리\n",
    "import torch\n",
    "import torch.nn as nn #신경망을 생성하고 학습을 도움, 잘 디자인된 모듈과 클래스들을 제공\n",
    "import torch.nn.functional as F \n",
    "from torch.utils.data import random_split \n",
    "     #데이터 세트를 분리하기 위해 torch.utils.data에서 random_split 함수를 포함시킵\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from torch.utils.data import random_split, SubsetRandomSampler \n",
    "     #트레이닝 및 테스트 데이터 지정\n",
    "from torchvision import datasets, transforms, models #터치비전에서 데이터 가져오기\n",
    "from torchvision.datasets import ImageFolder \n",
    "     #대용량 이미지 데이터를 데이터셋을 관리하기 편한 모듈\n",
    "from torchvision.transforms import ToTensor #이미지를 텐서로 변환\n",
    "from torchvision.utils import make_grid #그리드 만들기\n",
    "from pytorch_lightning import LightningModule\n",
    "     #lightning module은 trainer와 model이 상호작용할 수 있게 해주는 구현체\n",
    "from pytorch_lightning import Trainer\n",
    "import pytorch_lightning as pl\n",
    "import matplotlib.pyplot as plt \n",
    "     #모듈의 각각의 함수를 사용해서 간편하게 그래프를 만들고 변화를 줄 수 있음\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split #테스트, 검증 데이터 구분\n",
    "from sklearn.metrics import classification_report \n",
    "     #sklearn.metrics에서 라이브러리 불러오기\n",
    "from PIL import Image #이미지처리 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "03bcbe96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#이미지 조정\n",
    "transform=transforms.Compose([\n",
    "        transforms.RandomRotation(10),      # 회전 +/- 10 degrees\n",
    "        transforms.RandomHorizontalFlip(),  # 반전 50% of images\n",
    "        transforms.Resize(224),             # 리사이즈 짧은쪽을 224 pixel로\n",
    "        transforms.CenterCrop(224),         # 긴쪽을 중심에서 224 pixel로\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "a5c3401b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Abra', 'Aerodactyl', 'Alakazam', 'Alolan Sandslash', 'Arbok', 'Arcanine', 'Articuno', 'Beedrill', 'Bellsprout', 'Blastoise', 'Bulbasaur', 'Butterfree', 'Caterpie', 'Chansey', 'Charizard', 'Charmander', 'Charmeleon', 'Clefable', 'Clefairy', 'Cloyster', 'Cubone', 'Dewgong', 'Diglett', 'Ditto', 'Dodrio', 'Doduo', 'Dragonair', 'Dragonite', 'Dratini', 'Drowzee', 'Dugtrio', 'Eevee', 'Ekans', 'Electabuzz', 'Electrode', 'Exeggcute', 'Exeggutor', 'Farfetchd', 'Fearow', 'Flareon', 'Gastly', 'Gengar', 'Geodude', 'Gloom', 'Golbat', 'Goldeen', 'Golduck', 'Golem', 'Graveler', 'Grimer', 'Growlithe', 'Gyarados', 'Haunter', 'Hitmonchan', 'Hitmonlee', 'Horsea', 'Hypno', 'Ivysaur', 'Jigglypuff', 'Jolteon', 'Jynx', 'Kabuto', 'Kabutops', 'Kadabra', 'Kakuna', 'Kangaskhan', 'Kingler', 'Koffing', 'Krabby', 'Lapras', 'Lickitung', 'Machamp', 'Machoke', 'Machop', 'Magikarp', 'Magmar', 'Magnemite', 'Magneton', 'Mankey', 'Marowak', 'Meowth', 'Metapod', 'Mew', 'Mewtwo', 'Moltres', 'MrMime', 'Muk', 'Nidoking', 'Nidoqueen', 'Nidorina', 'Nidorino', 'Ninetales', 'Oddish', 'Omanyte', 'Omastar', 'Onix', 'Paras', 'Parasect', 'Persian', 'Pidgeot', 'Pidgeotto', 'Pidgey', 'Pikachu', 'Pinsir', 'Poliwag', 'Poliwhirl', 'Poliwrath', 'Ponyta', 'Porygon', 'Primeape', 'Psyduck', 'Raichu', 'Rapidash', 'Raticate', 'Rattata', 'Rhydon', 'Rhyhorn', 'Sandshrew', 'Sandslash', 'Scyther', 'Seadra', 'Seaking', 'Seel', 'Shellder', 'Slowbro', 'Slowpoke', 'Snorlax', 'Spearow', 'Squirtle', 'Starmie', 'Staryu', 'Tangela', 'Tauros', 'Tentacool', 'Tentacruel', 'Vaporeon', 'Venomoth', 'Venonat', 'Venusaur', 'Victreebel', 'Vileplume', 'Voltorb', 'Vulpix', 'Wartortle', 'Weedle', 'Weepinbell', 'Weezing', 'Wigglytuff', 'Zapdos', 'Zubat']\n",
      "150\n"
     ]
    }
   ],
   "source": [
    "dataset0=datasets.ImageFolder(root=\"./data/PokemonData/\",transform=None)\n",
    "        #지정된 경로로 데이터 불러오기\n",
    "class_names=dataset0.classes\n",
    "print(class_names) #데이터 클래스 이름 프린트\n",
    "print(len(class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "d89896d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataModule(pl.LightningDataModule): \n",
    "        #파이토치 라이트닝의 데이터모듈 클래스를 활용해서 트레이닝을 위한 데이터 준비와 구성\n",
    "    \n",
    "    def __init__(self, transform=transform, batch_size=32): \n",
    "        #배치 파라미터 설정(적정한 파라미터를 찾기 위해 여러번 진행함)\n",
    "        super().__init__()\n",
    "        self.root_dir = \"./data/PokemonData/\"\n",
    "        self.transform = transform\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        dataset = datasets.ImageFolder(root=self.root_dir, transform=self.transform)\n",
    "        n_data = len(dataset)\n",
    "        n_train = int(0.8 * n_data) #트레이닝 데이터와 테스트 데이터를 랜덤으로 8대2 비율로 적용\n",
    "        n_test = n_data - n_train\n",
    "\n",
    "        train_dataset, test_dataset = torch.utils.data.random_split(dataset, [n_train, n_test])\n",
    "\n",
    "        self.train_dataset = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "        self.test_dataset = DataLoader(test_dataset, batch_size=self.batch_size)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return self.train_dataset\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return self.test_dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "d0940705",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import ImageFolder\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "class BetterCNN(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super(BetterCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, 1) \n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, 1)\n",
    "        self.fc1 = nn.Linear(128 * 12 * 12, 512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, len(class_names))\n",
    "        self.dropout = nn.Dropout(0.5) # drop out레이어로 전체 레이어 추가 후 오버피팅을 줄인다.\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.pool(F.relu(self.conv1(X)))\n",
    "        X = self.pool(F.relu(self.conv2(X)))\n",
    "        X = self.pool(F.relu(self.conv3(X)))\n",
    "        X = X.view(-1, 128 * 12 * 12)#파라미터 변경(-1, 16 * 54 * 54)\n",
    "        X = F.relu(self.fc1(X))\n",
    "        X = self.dropout(X)\n",
    "        X = F.relu(self.fc2(X))\n",
    "        X = self.dropout(X)\n",
    "        X = self.fc3(X)\n",
    "        return F.log_softmax(X, dim=1)\n",
    "\n",
    "    def configure_optimizers(self):#아담을 옵티마이저로\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.0001)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        X, y = train_batch\n",
    "        y_hat = self(X)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        pred = y_hat.argmax(dim=1, keepdim=True)\n",
    "        acc = pred.eq(y.view_as(pred)).sum().item() / y.shape[0]\n",
    "        self.log(\"train_loss\", loss)\n",
    "        self.log(\"train_acc\", acc)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        X, y = val_batch\n",
    "        y_hat = self(X)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        pred = y_hat.argmax(dim=1, keepdim=True)\n",
    "        acc = pred.eq(y.view_as(pred)).sum().item() / y.shape[0]\n",
    "        self.log(\"val_loss\", loss)\n",
    "        self.log(\"val_acc\", acc)\n",
    "\n",
    "    def test_step(self, test_batch, batch_idx):\n",
    "        X, y = test_batch\n",
    "        y_hat = self(X)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        pred = y_hat.argmax(dim=1, keepdim=True)\n",
    "        acc = pred.eq(y.view_as(pred)).sum().item() / y.shape[0]\n",
    "        self.log(\"test_loss\", loss)\n",
    "        self.log(\"test_acc\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11060ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name  | Type   | Params\n",
      "---------------------------------\n",
      "0 | conv1 | Conv2d | 168   \n",
      "1 | conv2 | Conv2d | 880   \n",
      "2 | fc1   | Linear | 5.6 M \n",
      "3 | fc2   | Linear | 10.2 K\n",
      "4 | fc3   | Linear | 1.7 K \n",
      "5 | fc4   | Linear | 3.1 K \n",
      "---------------------------------\n",
      "5.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.6 M     Total params\n",
      "22.460    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "344cc3ae26dc4b2bbfe0070eb241e957",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    datamodule = DataModule()\n",
    "    datamodule.setup()\n",
    "    model = ConvolutionalNetwork()\n",
    "    trainer = pl.Trainer(max_epochs=50)#epoch 조절\n",
    "    trainer.fit(model, datamodule)\n",
    "    datamodule.setup(stage='test')\n",
    "    test_loader = datamodule.test_dataloader()\n",
    "    trainer.test(dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08143b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#파이토치 데이터로더로부터 이미지 시각화\n",
    "\n",
    "for images, labels in datamodule.train_dataloader(): #데이터 로딩 및 이미지 시각화 구성 설정\n",
    "    break\n",
    "im=make_grid(images,nrow=16)\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.imshow(np.transpose(im.numpy(),(1,2,0)))\n",
    "\n",
    "#노멀랑이징 후 이미지 그리드 만들기\n",
    "inv_normalize=transforms.Normalize(mean=[-0.485/0.229,-0.456/0.224,-0.406/0.225],\n",
    "                                   std=[1/0.229,1/0.224,1/0.225])\n",
    "im=inv_normalize(im)\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.imshow(np.transpose(im.numpy(),(1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766bc477",
   "metadata": {},
   "outputs": [],
   "source": [
    "#slearn.metrics에서 classification_report기능을 활용하여 파이토치 모델 평가\n",
    "\n",
    "device = torch.device(\"cpu\") #cpu를 디바이스로 설정\n",
    "\n",
    "model.eval() #모델 평가 모드로 설정\n",
    "y_true=[]\n",
    "y_pred=[]\n",
    "with torch.no_grad(): \n",
    "    for test_data in datamodule.test_dataloader():#테스트 데이터배치 반복\n",
    "        test_images, test_labels = test_data[0].to(device), test_data[1].to(device)\n",
    "        #테스트 데이터 계산을 위해서 (CPU/GPU)로 전송\n",
    "        pred = model(test_images).argmax(dim=1)\n",
    "        #테스트 이미지들을 모델을 거쳐서 예측 값 구하기\n",
    "        #argmax를 이용해서 가능한 최고값 클래스를 선택\n",
    "        for i in range(len(pred)):#반복 실행\n",
    "            y_true.append(test_labels[i].item())\n",
    "            y_pred.append(pred[i].item())\n",
    "\n",
    "print(classification_report(y_true,y_pred,target_names=class_names,digits=4)) #출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bf7547",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer, batch, epoch 등의 파라미터들을 조정해가며 성능체크를 진행하였다. \n",
    "#결과적으로 기존 프로젝트 정확도 47%에서 60~70%의 정확도로 개선할 수 있었다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af360f24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
